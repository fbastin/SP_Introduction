\documentclass[usepdftitle=false]{beamer}

\usepackage[utf8]{inputenc}
\usetheme{Singapore}
\usepackage{xcolor}
\setbeamertemplate{footline}[frame number]

\author[Fabian Bastin]{Fabian Bastin \\ \url{fabian.bastin@umontreal.ca} \\ Université de Montréal -- CIRRELT -- IVADO -- Fin-ML}
\date{}
\title[Linear programming]{KKT conditions\\Background material}

\usepackage{enumerate}
%\usepackage[francais]{babel}

\usepackage{easybmat}
\usepackage{graphicx}

\newtheorem{defn}{Definition}
\newtheorem{lem}{Lemma}
\newtheorem{thm}{Theorem}
\newtheorem{coro}{Corollary}

\def\red{\color{red}}
\def\blue{\color{blue}}

\input{macros}

\setbeamertemplate{footline}[frame number]

\begin{document}
\frame{\titlepage}

% ------------------------------------------------------------------------------------------------------------------------------------------------------

\begin{frame}
\frametitle{Basic notions}

Consider the problem
\begin{align*}
	\min_{x \in \mathbb{R}^n} \ & f(x) \\
	\mbox{subject to } & g_i(x) \leq 0,\ i = 1,\ldots,m, \\
	& h_j(x) = 0,\ j = 1,\ldots,r.
\end{align*}

The feasible set is
$$
\calX = \{ x \,|\, g_i(x) \leq 0, i = 1,\ldots,m, h_j(x) = 0, j = 1,\ldots,r \}.
$$

$x^*$ is a global minimizer of $f(\cdot)$ if $\forall x \in \calX$, $f(x^*) \leq f(x)$.

$x^*$ is a local minimizer of $f(\cdot)$ if
$\exists \epsilon > 0$ such that $\forall x \in \calB(x^*, \epsilon) \cap \calX$, $f(x^*) \leq f(x).$

\end{frame}

\begin{frame}
	\frametitle{Lagrangian and Lagrangian dual function}
	
We define the Lagrangian as
	$$
	L(x, \lambda, \mu) = f(x) + \sum_{i = 1}^m \lambda_i g_i(x)
	+ \sum_{j = 1}^r \mu_j h_j(x),
	$$
and the dual Lagrangian function
	$$
	\calL(\lambda, \mu) = \min_{x \in \mathbb{R}^n} L(x, \lambda, \mu).
	$$
	
\end{frame}

\begin{frame}
\frametitle{Lagrange multipliers: equality constraints}

Consider the mathematical program
\begin{align*}
\min_{x \in \calX} \ & f(x) \\
\mbox{subject to } & g_i(x) = 0,\ i = 1,\ldots,m,
\end{align*}
where $\calX \subset \RR^n$, $f: \RR^n \rightarrow \RR$, $g_i: \RR^n \rightarrow \RR$, $i = 1,\ldots,m$.

\mbox{}

The {\red Lagrangian} of this problem is obtained by associating a Lagrange multiplier  $\lambda_i$ to each constraint function $g_i$:
$$
L(x, \lambda) = f(x) + \sum_{i = 1}^{m} \lambda_i g_i(x).
$$

We can obtain very general conditions under which $x^*$ is an optimal solution to the optimization problem, while only basic assumptions are made over $\calX$ and the functions $f$ and $g_i$, $i = 1,\ldots,m$.

\end{frame}

\begin{frame}
\frametitle{Optimality}

\begin{thm}
Assume that the Lagrangian associated to the problem
\begin{align*}
\min_{x \in \calX} \ & f(x) \\
\mbox{s.t. } & g_i(x) = 0,\ i = 1,\ldots,m,
\end{align*}
has a local minimizer $x^* \in \calX$ when the multiplier vector $\lambda$ is equal to $\lambda^*$.
If $g_i(x^*) = 0$, $i = 1,\ldots,m$, then $x^*$ if a local minimizer of $f(x)$.
\end{thm}

\end{frame}

\begin{frame}
\frametitle{Optimality}

\begin{proof}
Assume by contradiction that $x^*$ is not a local minimizer of $f(x)$.
Then $\forall \epsilon > 0$, $\exists\, \overline{x} \in \calB(x^*, \epsilon)$ such that $g_i(\overline{x}) = 0$, $i = 1,\ldots,m$, and $f(\overline{x}) < f(x^*)$.
	
Thus, $\forall \lambda$,
	$$
	\sum_{i = 1}^{m} \lambda_i g_i(x^*) = \sum_{i = 1}^{m} \lambda_i g_i(\overline{x}) = 0,
	$$
and
$$
f(\overline{x}) + \sum_{i = 1}^{m} \lambda_i g_i(\overline{x}) < f(x^*) + \sum_{i = 1}^{m} \lambda_i g_i(x^*).
$$
Taking $\lambda = \lambda^*$, the previous inequality contradicts that $x^*$ is a local minimizer of the Lagrangian when $\lambda = \lambda^*$.
\end{proof}

\end{frame}

\begin{frame}
\frametitle{Lagrange multipliers: inequality constraints}

Consider the mathematical program
\begin{align*}
\min_{x \in \calX} \ & f(x) \\
\mbox{subject to } & g_i(x) \leq 0,\ i = 1,\ldots,m.
\end{align*}
where $\calX \subset \RR^n$, $f: \RR^n \rightarrow \RR$, $g_i: \RR^n \rightarrow \RR$, $i = 1,\ldots,m$.

\mbox{}

\begin{thm}
Assume that the Lagrangian associated to the problem
\begin{align*}
\min_{x \in \calX} \ & f(x) \\
\mbox{s.t. } & g_i(x) \leq 0,\ i = 1,\ldots,m,
\end{align*}
has a local minimum $x^* \in \calX$ when the multipliers vector $\lambda$ is equal to $\lambda^*$.
If $g_i(x^*) \leq 0$, $\lambda^*_i \geq 0$, and $\lambda^*_i g_i(x^*) = 0$, $i = 1,\ldots,m$, then $x^*$ is a local minimum of $f(x)$.
\end{thm}

\end{frame}

\begin{frame}
\frametitle{Lagrange multipliers: inequality constraints}
	
\begin{proof}
	As previously, assume by contradiction that $x^*$ is not a local minimizer of $f(x)$.
Then $\forall \epsilon > 0$, $\exists\, \overline{x} \in \calB(x^*, \epsilon)$ such that $g_i(\overline{x}) \leq 0$, $i = 1,\ldots,m$ and $f(\overline{x}) < f(x^*)$.
Therefore, for $\lambda = \lambda^* \geq 0$,
$$
\sum_{i = 1}^{m} \lambda_i g_i(\overline{x}) \leq 0 \mbox{ and }
\sum_{i = 1}^{m} \lambda_i g_i(x^*) = 0.
$$
Consequently,
$$
f(\overline{x}) + \sum_{i = 1}^{m} \lambda_i g_i(\overline{x}) < f(x^*) + \sum_{i = 1}^{m} \lambda_i g_i(x^*),
$$
contradicting that $x^*$ is a local minimizer of the Lagrangian when $\lambda = \lambda^*$.
\end{proof}

\end{frame}

\begin{frame}
\frametitle{Dual problem}

The dual problem is
\begin{align*}
\max_{\lambda \in \RR^m, \mu \in \RR^r}\ & \calL(\lambda, \mu) \\
\mbox{such that } & \lambda \geq 0.
\end{align*}

Important properties:
\begin{itemize}
\item
The dual problem is always convex, i.e. $\calL$ is always concave (even if the primal problem is not convex).
\item
The primal and dual (global) optimal values, $f^*$ and $\calL^*$, always satisfy the weak duality: $f^* \geq \calL^*$.
\item {\blue Strong duality}: under some conditions (constraint qualifications), $f^* = \calL^*$.
\end{itemize}

\end{frame}

\begin{frame}
\frametitle{Duality gap}

Given a primal feasible solution $x$ and a dual feasible solution $(\lambda, \mu)$, the quantity $f(x) - \calL(\lambda, \mu)$ is called the duality gap between $x$ and $(\lambda, \mu)$.
Note that
$$
f(x) - f^* \leq f(x) - \calL(\lambda, \mu).
$$
Therefore, if the duality gap is equal to 0, then $x$ is primal-optimal (and similarly, $\lambda$ and $\mu$ are dual-optimal).

\mbox{}

From an algorithmic point of view, if strong duality holds, this provides a stopping criterion: if $f(x) - \calL(\lambda, \mu) \leq \epsilon$, then $f(x) - f^* \leq \epsilon$.

\end{frame}

\begin{frame}
\frametitle{Duality gap: local case}

We can also define the dual Lagrangian function restricted to the ball $\calB(x^*, \epsilon)$:
$$
\calL_{\calB(x^*, \epsilon)}(\lambda, \mu) = \min_{x \in \calB(x^*, \epsilon)} L(x,\lambda, \mu).
$$
The weak duality still holds locally:
$$
\calL^*_{\calB(x^*, \epsilon)} \leq f(x^*).
$$
Under some conditions, the strong duality also holds:
$$
\calL^*_{\calB(x^*, \epsilon)} = f(x^*).
$$

\end{frame}

\begin{frame}
\frametitle{Duality gap: local case}

Note however that
$$
\min_{x \in \mathbb{R}^n} L(x, \lambda, \mu) 
\leq \min_{x \in \calB(x^*, \epsilon)} L(x, \lambda, \mu) 
$$
so
$$
\calL^* \leq \calL^*_{\calB(x^*, \epsilon)}.
$$

\mbox{}

Therefore, if $x^*$ is a local minimizer and the strong duality locally holds,
$$
\calL^* \leq f(x^*).
$$
The inequality can be strict.

\end{frame}

\begin{frame}
	\frametitle{Karush-Kuhn-Tucker (KKT) conditions}
	
	Consider $f, g_i, h_j \in C^1$, $i = 1,\ldots,m$, $j = 1,\ldots,r$, and the problem
	\begin{align*}
		\min_{x \in \mathbb{R}^n} \ & f(x) \\
		\mbox{s.t. } & g_i(x) \leq 0,\ i = 1,\ldots,m, \\
		& h_j(x) = 0,\ j = 1,\ldots,r.
	\end{align*}
	
	Karush-Kuhn-Tucker (KKT) conditions:
	\begin{align*}
		\nabla_x L(x,\lambda,\mu) &= 0 & \mbox{(stationarity)}\\
		\lambda_i g_i(x) &= 0 & \mbox{(complementarity)} \\
		g_i(x) \leq 0, &\ h_j(x) = 0\ \forall i,j & \mbox{(primal feasibility)} \\
		\lambda_i &\geq 0\ \forall i & \mbox{(dual feasibility)}
	\end{align*}
	
\end{frame}

\begin{frame}
	\frametitle{Necessary conditions}
	
	Let $x^*$ be a minimizer of $f(\cdot)$ in $\calB(x^*,\epsilon)$, $\epsilon > 0$, and $(\lambda^*, \mu^*)$ be a dual solution if $x$ is restricted to $\calB(x^*,\epsilon)$, with a zero duality gap (the strong duality holds). Then
	\begin{align*}
		f(x^*) &= \calL_{\calB(x^*, \epsilon)}(\lambda^*, \mu^*) \\
		&= \min_{x \in \calB(x^*,\epsilon)} \left( f(x) + \sum_{i = 1}^m \lambda_i^* g_i(x) + \sum_{i = 1}^r \mu_i^* h_i(x) \right) \\
		& \leq f(x^*) + \sum_{i = 1}^m \lambda_i^* g_i(x^*) + \sum_{i = 1}^r \mu_i^* h_i(x^*) \\
		& \leq f(x^*)
	\end{align*}
	Thus, $x^*$ is a minimizer of $L(x, \lambda^*, \mu^*)$ in $\calB(x^*,\epsilon)$, and $\nabla_x L(x^*, \lambda^*, \mu^*) = 0$.
	
	\mbox{}
	
We have obtained the stationarity conditions.
	
\end{frame}

\begin{frame}
	\frametitle{Necessary conditions}
	
	The previous inequalities also imply $\sum_{i = 1}^m \lambda_i^* g_i(x^*) = 0$ as $\sum_{i = 1}^m \lambda_i^* g_i(x^*) \leq 0$, and consequently, $\lambda_i^* g_i(x^*) = 0,\ \forall i$.
	
	\mbox{}
	
	This establishes the complementarity conditions.
	
	\mbox{}
	
	If $x^*$ is a global minimizer, we can replace $\calB(x^*,\epsilon)$ by $\RR^n$.
	
	\mbox{}
	
	We can summarize our findings in the theorem below.
\begin{thm}[KKT necessary conditions]
	If $x^*$, $(\lambda^*, \mu^*)$ are primal and dual solutions with a null duality gap, then $x^*$, $(\lambda^*, \mu^*)$ satisfy the KKT conditions.
\end{thm}

\end{frame}

\begin{frame}
\frametitle{Strong duality}

\mbox{}

The strong duality assumption often plays a key role. How to ensure that it holds?
\begin{itemize}
\item
Linear programming. It always holds.
\item
Convex programming. Slater condition: $\exists x$ such that $g_i(x) < 0$, $i = 1,\ldots,m$ et $h_i(x) = 0$, $i = 1,\ldots,r$.
\item
Nonconvex programming. Constraint qualification hypothesis. The most common, while the most restrictive, is the linear independence constraint qualification (LICQ).
\end{itemize}

\end{frame}

\begin{frame}
\frametitle{Nonconvex programming}

\begin{thm}[Necessary conditions]
If $x^*$ is a local solution of
\begin{align*}
\min_{x \in \calX} \ & f(x) \\
\mbox{s.t. } & g_i(x) \leq 0,\ i = 1,\ldots,m \\
& h_i(x) = 0,\ i = 1,\ldots,r,
\end{align*}
where $f$, $g_i$ et $h_i$, $i = 1,\ldots,m$, $\in C^1$, and a constraint qualification condition holds at $x^*$, then
$\exists (\lambda^*, \mu^*)$ such that the KKT conditions hold at $(x^*,\lambda^*, \mu^*)$.
\end{thm}

\begin{proof}
See Nocedal \& Wright, ``Numerical Optimization'', Section 12.4.
\end{proof}

\end{frame}

\begin{frame}
	\frametitle{Sufficiency of KKT conditions}
	
	If $\exists\, x^*$, $(\lambda^*, \mu^*)$ satisfying the KKT conditions, then
	$$
	L(\lambda^*, \mu^*) = f(x^*) + \sum_{i = 1}^m \lambda_i^* g_i(x^*) + \sum_{i = 1}^r \mu_i^* h_i(x^*) = f(x^*)
	$$
	Thus, the duality gap is null ({\red strong duality}).
		
	\mbox{}
	
	In the convex case, this implies that $x^*$ and $(\lambda^*, \mu^*)$ are global primal and dual optimal solutions, respectively.

	\mbox{}

	In the nonconvex case, $x^*$ is a local minimizer, not necessarily global, or a saddle point.
	% donner un exemple du dernier cas
	
	%Si $x^*$ n'est pas un minimum global, la fonction dual lagrangienne n'est pas non plus minimisée globalement. Si on considère le minimum global de la fonction duale lagrangienne, le saut de dualité n'est pas nul.
	
\end{frame}

\begin{frame}
\frametitle{Active set}

\begin{defn}[Active set]
The active set $\calA(x)$ of the optimization problem
\begin{align*}
\min_{x \in \calX} \ & f(x) \\
\mbox{s.t. } & g_i(x) \leq 0,\ i \in \calI \\
& h_i(x) = 0,\ i \in \calE,
\end{align*}
in a feasible point $x$ is the index set of the equality constraints and the active inequality constraints at that point:
$$
\calA(x) = \calE U \{ i \,|\, g_i(x) = 0 \}
$$
\end{defn}

\end{frame}

\begin{frame}
\frametitle{LICQ}

The most popular constraint qualification is the LICQ.

\begin{defn}[LICQ]
Given the point $x$ and the active set $\calA(x)$, the linear independence constraint qualification (LICQ) holds if the gradients of the active constraints, $\{\nabla_x c_i(x), i \in \calA(x)\}$, are linearly independent.
\end{defn}

\end{frame}

\end{document}